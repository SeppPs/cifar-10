{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet_cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7h9KvQ5LQAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "3b0cab7e-0004-4e74-ad51-2c95013d6c58"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\n",
        "assert(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
        "!pip install -U efficientnet\n",
        "import efficientnet.keras as efn \n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/28/91/67848a143b54c331605bfba5fd31cf4e9db13d2e429d103fe807acc3bcf4/efficientnet-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Installing collected packages: efficientnet\n",
            "Successfully installed efficientnet-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeQ9sdQTPAe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # The default batch size of keras.\n",
        "num_classes = 100  # Number of class for the dataset\n",
        "epochs = 150\n",
        "data_augmentation = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS30WZWZPBQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "78092cc4-bcb1-4be7-d35d-f735dd6d1e39"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnEp-t-6PDdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biYpkhcQO42p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "63f04576-6585-41aa-e049-7e275b97ee03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyCPqZhxMV9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c0fae48f-1699-408c-b3d4-8c49e78e9354"
      },
      "source": [
        "base_model = tf.keras.applications.InceptionResNetV2(weights = 'imagenet', include_top=False, input_shape=[75,75,3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUh4XY-OWGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.UpSampling2D())\n",
        "model.add(tf.keras.layers.UpSampling2D())\n",
        "# model.add(tf.keras.layers.UpSampling2D())\n",
        "model.add(base_model)\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(2048, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(256, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpui-xpHQnjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "969b21be-9901-44f7-dde5-83deecb4e026"
      },
      "source": [
        "model.build(input_shape = [None,32,32,3])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 75, 75, 3) for input Tensor(\"input_1:0\", shape=(None, 75, 75, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) multiple                  0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Model)  (None, 1, 1, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  3147776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  524544    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  2570      \n",
            "=================================================================\n",
            "Total params: 58,011,626\n",
            "Trainable params: 57,951,082\n",
            "Non-trainable params: 60,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K7SeoPYAmgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate=0.005, momentum = 0.9)\n",
        "\n",
        "# Let's train the model using RMSproptf.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tM5IycKg61g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters for callback functions\n",
        "es_patience = 10\n",
        "rlrop_patience = 5\n",
        "decay_rate = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WKaKQygQo8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df3f582f-0deb-4141-d75e-72c02e864e03"
      },
      "source": [
        "history = None  # For recording the history of trainning process.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    my_callbacks = [\n",
        "      tf.keras.callbacks.EarlyStopping(patience=25),\n",
        "      tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5',\n",
        "                                         save_best_only=True, monitor='val_loss', mode='min'),\n",
        "    ]\n",
        "    history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=my_callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.15,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "    my_callbacks = [\n",
        "      tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/My Drive/Colab Notebooks/best_model_cifar10_InceptionResNetV2.h5',\n",
        "                                        save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "      tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 15, restore_best_weights = True, verbose = 1),\n",
        "      tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 5, factor = decay_rate, min_lr = 1e-6, verbose = 1)\n",
        "    ]\n",
        "    # Fit the model on the batches generated by datagen.flow()."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvQ7EDY1osns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c736a9af-0a9b-4740-d397-95ecb1cb1042"
      },
      "source": [
        "model.fit(datagen.flow(x_train, y_train,\n",
        "                        batch_size=batch_size),\n",
        "                        shuffle = True,\n",
        "                        steps_per_epoch=len(x_train) / 64,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        callbacks=my_callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.7593WARNING:tensorflow:Model was constructed with shape (None, 75, 75, 3) for input Tensor(\"input_1:0\", shape=(None, 75, 75, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
            "782/781 [==============================] - 285s 364ms/step - loss: 0.7004 - accuracy: 0.7593 - val_loss: 0.2385 - val_accuracy: 0.9193 - lr: 0.0050\n",
            "Epoch 2/150\n",
            "782/781 [==============================] - 281s 359ms/step - loss: 0.2924 - accuracy: 0.9027 - val_loss: 0.1810 - val_accuracy: 0.9362 - lr: 0.0050\n",
            "Epoch 3/150\n",
            "782/781 [==============================] - 281s 359ms/step - loss: 0.2170 - accuracy: 0.9266 - val_loss: 0.1633 - val_accuracy: 0.9422 - lr: 0.0050\n",
            "Epoch 4/150\n",
            "782/781 [==============================] - 280s 359ms/step - loss: 0.1745 - accuracy: 0.9420 - val_loss: 0.1419 - val_accuracy: 0.9533 - lr: 0.0050\n",
            "Epoch 5/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.1467 - accuracy: 0.9504 - val_loss: 0.1566 - val_accuracy: 0.9484 - lr: 0.0050\n",
            "Epoch 6/150\n",
            "782/781 [==============================] - 279s 357ms/step - loss: 0.1265 - accuracy: 0.9580 - val_loss: 0.1460 - val_accuracy: 0.9549 - lr: 0.0050\n",
            "Epoch 7/150\n",
            "782/781 [==============================] - 281s 359ms/step - loss: 0.1089 - accuracy: 0.9639 - val_loss: 0.1411 - val_accuracy: 0.9583 - lr: 0.0050\n",
            "Epoch 8/150\n",
            "782/781 [==============================] - 274s 351ms/step - loss: 0.0973 - accuracy: 0.9680 - val_loss: 0.1428 - val_accuracy: 0.9558 - lr: 0.0050\n",
            "Epoch 9/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0874 - accuracy: 0.9705 - val_loss: 0.1423 - val_accuracy: 0.9549 - lr: 0.0050\n",
            "Epoch 10/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.1786 - val_accuracy: 0.9490 - lr: 0.0050\n",
            "Epoch 11/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0896 - accuracy: 0.9697 - val_loss: 0.1411 - val_accuracy: 0.9576 - lr: 0.0050\n",
            "Epoch 12/150\n",
            "782/781 [==============================] - 281s 359ms/step - loss: 0.0667 - accuracy: 0.9778 - val_loss: 0.1384 - val_accuracy: 0.9592 - lr: 0.0050\n",
            "Epoch 13/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0628 - accuracy: 0.9787 - val_loss: 0.1354 - val_accuracy: 0.9591 - lr: 0.0050\n",
            "Epoch 14/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.1433 - val_accuracy: 0.9585 - lr: 0.0050\n",
            "Epoch 15/150\n",
            "782/781 [==============================] - 281s 359ms/step - loss: 0.0526 - accuracy: 0.9824 - val_loss: 0.1379 - val_accuracy: 0.9628 - lr: 0.0050\n",
            "Epoch 16/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0488 - accuracy: 0.9840 - val_loss: 0.1435 - val_accuracy: 0.9611 - lr: 0.0050\n",
            "Epoch 17/150\n",
            "782/781 [==============================] - 282s 360ms/step - loss: 0.0472 - accuracy: 0.9841 - val_loss: 0.1315 - val_accuracy: 0.9629 - lr: 0.0050\n",
            "Epoch 18/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 0.1455 - val_accuracy: 0.9609 - lr: 0.0050\n",
            "Epoch 19/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.1494 - val_accuracy: 0.9610 - lr: 0.0050\n",
            "Epoch 20/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.1410 - val_accuracy: 0.9589 - lr: 0.0050\n",
            "Epoch 21/150\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.1457 - val_accuracy: 0.9609 - lr: 0.0050\n",
            "Epoch 22/150\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9892\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "782/781 [==============================] - 275s 352ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.1410 - val_accuracy: 0.9618 - lr: 0.0050\n",
            "Epoch 23/150\n",
            "782/781 [==============================] - 280s 358ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.1368 - val_accuracy: 0.9642 - lr: 0.0025\n",
            "Epoch 24/150\n",
            "782/781 [==============================] - 280s 358ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.1273 - val_accuracy: 0.9671 - lr: 0.0025\n",
            "Epoch 25/150\n",
            "782/781 [==============================] - 279s 357ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.1363 - val_accuracy: 0.9676 - lr: 0.0025\n",
            "Epoch 26/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.1367 - val_accuracy: 0.9675 - lr: 0.0025\n",
            "Epoch 27/150\n",
            "782/781 [==============================] - 279s 357ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.1320 - val_accuracy: 0.9687 - lr: 0.0025\n",
            "Epoch 28/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.1430 - val_accuracy: 0.9657 - lr: 0.0025\n",
            "Epoch 29/150\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9948\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1421 - val_accuracy: 0.9654 - lr: 0.0025\n",
            "Epoch 30/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.1362 - val_accuracy: 0.9679 - lr: 0.0012\n",
            "Epoch 31/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.1410 - val_accuracy: 0.9683 - lr: 0.0012\n",
            "Epoch 32/150\n",
            "782/781 [==============================] - 279s 356ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.1347 - val_accuracy: 0.9698 - lr: 0.0012\n",
            "Epoch 33/150\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1437 - val_accuracy: 0.9684 - lr: 0.0012\n",
            "Epoch 34/150\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "782/781 [==============================] - 274s 350ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1471 - val_accuracy: 0.9670 - lr: 0.0012\n",
            "Epoch 35/150\n",
            "782/781 [==============================] - 275s 351ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.1424 - val_accuracy: 0.9683 - lr: 6.2500e-04\n",
            "Epoch 36/150\n",
            "782/781 [==============================] - 274s 351ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.1412 - val_accuracy: 0.9676 - lr: 6.2500e-04\n",
            "Epoch 37/150\n",
            "782/781 [==============================] - 275s 351ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.1413 - val_accuracy: 0.9683 - lr: 6.2500e-04\n",
            "Epoch 38/150\n",
            "782/781 [==============================] - 274s 351ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1363 - val_accuracy: 0.9696 - lr: 6.2500e-04\n",
            "Epoch 39/150\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "782/781 [==============================] - 275s 351ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1375 - val_accuracy: 0.9696 - lr: 6.2500e-04\n",
            "Epoch 00039: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8ff2dfc0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUTGJHyVAcm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}